
x-scrapy-common: &scrapy-common
  build:
    context: .
    dockerfile: compose/Dockerfile  # Use the merged Dockerfile
    args:
      BUILD_ENV: "production"  # Use production environment
  environment:
    - PYTHONUNBUFFERED=0
  depends_on:
    - selenium
  volumes:
    - ./data:/app/data

services:
  selenium:
    container_name: selenium
    image: selenium/standalone-chrome-debug
    ports:
      - "5900:5900"
    shm_size: 128M
    environment:
      - VNC_NO_PASSWORD=1

  scrapy_random:
    <<: *scrapy-common
    command: ["/start", "random"]

  scrapy_companies:
    <<: *scrapy-common
    command: ["/start_companies"]

  scrapy_byname:
    <<: *scrapy-common
    command: ["/start", "byname"]

  scrapy_test:
    build:
      context: .
      dockerfile: compose/Dockerfile  # Use the same merged Dockerfile
      args:
        BUILD_ENV: "local"  # Specify the local environment
    environment:
      - PYTHONUNBUFFERED=0
    depends_on:
      - selenium
    volumes:
      - .:/app
    command: [ "py.test", "tests/companies.py", "tests/selenium.py"]
